<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Comparación de Modelos y Correlaciones</title>
    <meta charset="utf-8" />
    <meta name="author" content="dacarras" />
    <script src="libs/header-attrs-2.12/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="animate.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">










class: title-slide, middle, center

background-image: url(img/background_01.jpeg)
background-size: 100%


.line_space_08[

## Metodología Cuantitativa Avanzada I

### .text_70[
Comparación de modelos GLM y Correlaciones
]

]

&lt;br&gt;
&lt;br&gt;

.line_space_03[
.white[

.text_70[

Carrasco, D., PhD

.text_60[Centro de Medición MIDE UC]

]

&lt;br&gt;

.text_70[PSI4035]

.text_70[Santiago, Marzo 23 de 2022]
  
  ]
]

&lt;br&gt;

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Comparación de modelos
]
]
]
.line_space_01[
Evalación global de los modelos
]


&lt;br&gt;
&lt;br&gt;

---

background-image: url(img/background_03.jpeg)
background-size: 100%

.pull_l_50_t_080[

### Comparación de modelos

Vik (2014, p50) emplea la siguiente tabla para evaluar al modelo ajusstado

- El estadístico F es un "ratio"
- Es la relación entre los MS (i.e., *mean square*) de cada modelo ajustado.
- Cada uno de estos MS proviene de la suma de cuadrados.
- Es la division de los SS por los grado de libertad (*df*).

- El modelo compacto o nulo, posee una suma de cuadrados (SS) de 80
 + esta es la variabilidad de las observaciones con respecto a la media.

- El modelo aumentado o modelo con un predictor, posee una suma de cuadrados de 15.617
 + esta es la variabilidad que nos queda, luego de restar los valores esperados sobre los valores observados (ver Tabla 3.3)

- El error explicado, es 64.383, porque es lo que logro reducirse en error
 + SS_total - SS_aumentado = SS_explicado
 + 80 - 15.617 =  64.383

]

.pull_r_50_t_080[

### Tabla 4.7

&lt;img src="./files/table_4.7_summary.jpg" width="100%" /&gt;

.text_90[

- Mientras más grande sea F, esto significa que hay más varianza explicada, que varianza por explicar.
- La distribución muestral F (i.e., la forma que sigue la distribución) es asimétrica positiva.
  + Esto quiere decir que, a mayores valores de F, uno espera que las chances de observar valores F de gran tamaño sea muy pequeña. Si nuestro valor F observado posee chances menores a %5 (por ejemplo), es convencional afirmar que nuestros resultados estan por sobre el azar.
  + En otras palabras, que nuestra distribucion de F, en muy pocas ocasiones genera nuestros datos observados. Y por tanto, podemos rechazar la hipotesis nula (ver Huck, 2012).
  + Con lo anterior, planteamos que nuestro modelo ajusta a los datos con tal o cual R2.

  ]
]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Comparación de modelos
]
]
]
.line_space_01[
Reajustemos los modelos
]


&lt;br&gt;
&lt;br&gt;

---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_50_t_090[

### Abrir y preparar datos


```r
#------------------------------------------------------------------------------
# datos
#------------------------------------------------------------------------------

#----------------------------------------------------------
# tabla 3.2
#----------------------------------------------------------

data_table_3_2 &lt;- read.table(
text="
person   y    x    x_q   xy   z
1        2    8     64   16   1
2        3    9     81   27   2
3        3    9     81   27   1
4        4   10    100   40   2
5        7    6     36   42   1
6        5    7     49   35   2
7        5    4     16   20   1
8        7    5     25   35   2
9        8    3      9   24   1
10       9    1      1    9   2
11       9    2      4   18   1
12      10    2      4   20   2

",
header=TRUE, stringsAsFactors = FALSE)

# Nota: agregamos a la variable z,
#       para ilustrar como se ve un
#       modelo que no explica a y.

#----------------------------------------------------------
# preparar datos
#----------------------------------------------------------

data_model &lt;- data_table_3_2 %&gt;%
              mutate(x_g = mean(x, na.rm = TRUE)) %&gt;%
              mutate(x_cgm = x - x_g) %&gt;%
              dplyr::select(y, x, x_cgm, z)
```

]

.pull_r_50_t_090[

### Ajustar modelos


```r
#------------------------------------------------------------------------------
# datos
#------------------------------------------------------------------------------

#--------------------------------------
# formulas
#--------------------------------------

f00 &lt;- as.formula(y ~ + 1)
f01 &lt;- as.formula(y ~ + 1 + x)
f02 &lt;- as.formula(y ~ + 1 + x_cgm)
f03 &lt;- as.formula(y ~ + 1 + z)

#--------------------------------------
# ajustar modelos
#--------------------------------------

m00 &lt;- lm(f00, data = data_model)
m01 &lt;- lm(f01, data = data_model)
m02 &lt;- lm(f02, data = data_model)
m03 &lt;- lm(f03, data = data_model)

#--------------------------------------
# comparar modelos de forma sintética
#--------------------------------------

texreg::screenreg(
    list(m00, m01, m02, m03),
    star.symbol = "*", 
    center = TRUE, 
    doctype = FALSE,
    dcolumn = TRUE, 
    booktabs = TRUE,
    single.row = FALSE
    )
```

]

---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_50_t_100[

### Ajustar modelos


```r
#------------------------------------------------------------------------------
# datos
#------------------------------------------------------------------------------

#--------------------------------------
# formulas
#--------------------------------------

f00 &lt;- as.formula(y ~ + 1)
f01 &lt;- as.formula(y ~ + 1 + x)
f02 &lt;- as.formula(y ~ + 1 + x_cgm)
f03 &lt;- as.formula(y ~ + 1 + z)

#--------------------------------------
# ajustar modelos
#--------------------------------------

m00 &lt;- lm(f00, data = data_model)
m01 &lt;- lm(f01, data = data_model)
m02 &lt;- lm(f02, data = data_model)
m03 &lt;- lm(f03, data = data_model)

#--------------------------------------
# comparar modelos de forma sintética
#--------------------------------------

texreg::screenreg(
    list(m00, m01, m02, m03),
    star.symbol = "*", 
    center = TRUE, 
    doctype = FALSE,
    dcolumn = TRUE, 
    booktabs = TRUE,
    single.row = FALSE
    )
```

]

.pull_r_50_t_100[

### Resultados de los modelos

```text

=====================================================
             Model 1    Model 2    Model 3    Model 4
-----------------------------------------------------
(Intercept)   6.00 ***  10.27 ***   6.00 ***   5.00  
             (0.78)     (0.76)     (0.36)     (2.56) 
x                       -0.78 ***                    
                        (0.12)                       
x_cgm                              -0.78 ***         
                                   (0.12)            
z                                              0.67   
                                              (1.62) 
-----------------------------------------------------
R^2           0.00       0.80       0.80       0.02  
Adj. R^2      0.00       0.79       0.79      -0.08  
Num. obs.    12         12         12         12     
=====================================================
 *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05



```
&lt;br&gt;

El modelo 3 de la tabla anterior, llamado `m02` en nuestro código, es nuestro modelo de interes. Este fue ajustado con la formula `y ~ + 1 + x_cgm`. En la siguiente lámina vamos a aplicar la prueba de ANOVA o prueba F, para realizar una evaluación global.

]

---

background-image: url(img/background_03.jpeg)
background-size: 100%

.pull_l_50_t_100[

### Evaluación Global del Modelo


```r
#----------------------------------------------------------
# tabla 4.7 evaluación global
#----------------------------------------------------------

# tabla F de modelo aumentado
anova(m02)

# R2 del modelo
summary(m02)$r.squared
```

```text
# tabla F de modelo aumentado
&gt; anova(m02)
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value     Pr(&gt;F)    
x_cgm      1 64.383  64.383  41.227 0.00007627 ***
Residuals 10 15.617   1.562                       
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; 
&gt; # R2 del modelo
&gt; summary(m02)$r.squared
[1] 0.8047897

```

]



.pull_r_50_t_100[

### Tabla 4.7

&lt;img src="./files/table_4.7_summary.jpg" width="100%" /&gt;



]


---

background-image: url(img/background_03.jpeg)
background-size: 100%

.pull_l_50_t_100[

### Comparación entre Modelos


```r
#----------------------------------------------------------
# tabla 4.7 comparación de modelos (Vik, 2014, p50)
#----------------------------------------------------------

# tabla F de la comparación de modelos

anova(m00, m02)

# R2 del modelo
summary(m02)$r.squared
```

```text
# tabla F de modelo aumentado
&gt;anova(m00,  m02)
Analysis of Variance Table

Model 1: y ~ +1
Model 2: y ~ +1 + x_cgm
  Res.Df    RSS Df Sum of Sq      F     Pr(&gt;F)    
1     11 80.000                                   
2     10 15.617  1    64.383 41.227 0.00007627 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; 
&gt; # R2 del modelo
&gt; summary(m02)$r.squared
[1] 0.8047897

```

]


.pull_r_50_t_100[

### Tabla 4.7

&lt;img src="./files/table_4.7_summary.jpg" width="100%" /&gt;



]


---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Evaluación Global
]
]
]
.line_space_01[
Donde se encuentra cada componente en el output de R
]


&lt;br&gt;
&lt;br&gt;

---

### Evaluación Global

&lt;img src="./files/f_global_1.jpeg" width="90%" /&gt;

---
### Evaluación Global

&lt;img src="./files/f_global_2.jpeg" width="90%" /&gt;

---

### Evaluación Global

&lt;img src="./files/f_global_3.jpeg" width="90%" /&gt;

---

### Evaluación Global

&lt;img src="./files/f_global_4.jpeg" width="90%" /&gt;

---

### Evaluación Global

&lt;img src="./files/f_global_5.jpeg" width="90%" /&gt;

---


### Evaluación Global

&lt;img src="./files/f_global_6.jpeg" width="90%" /&gt;

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Comparación de Modelos
]
]
]
.line_space_01[
Donde se encuentra cada componente en el output de R
]


&lt;br&gt;
&lt;br&gt;


---
### Comparación de modelos

&lt;img src="./files/f_comp_1.jpeg" width="90%" /&gt;


---


### Comparación de modelos

&lt;img src="./files/f_comp_2.jpeg" width="90%" /&gt;

---

### Comparación de modelos

&lt;img src="./files/f_comp_3.jpeg" width="90%" /&gt;

---

### Comparación de modelos

&lt;img src="./files/f_comp_4.jpeg" width="90%" /&gt;

---

### Comparación de modelos

&lt;img src="./files/f_comp_5.jpeg" width="90%" /&gt;

---


### Comparación de modelos

&lt;img src="./files/f_comp_6.jpeg" width="90%" /&gt;

---


### Comparación de modelos

&lt;img src="./files/f_comp_7.jpeg" width="90%" /&gt;

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
¿Qué tan típico es nuestro modelo?
]
]
]
.line_space_01[
Cuáles son las chances de los resultados que estamos observando
]


&lt;br&gt;
&lt;br&gt;

---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_40[

.text_80[

```r
#------------------------------------------------------------------------------
# p value de la comparación modelos (m00, m02)
#------------------------------------------------------------------------------

# opciones de consola
options(scipen = 999)
options(digits = 7)

# valor p de la comparación de modelos
anova(m00, m02) %&gt;%
broom::tidy() %&gt;%
knitr::kable(., digits = 7)

# -----------------------------------------------
# f value
# -----------------------------------------------

f_value &lt;- anova(m00, m02) %&gt;%
           broom::tidy() %&gt;%
           mutate(model = c('compact', 'augmented')) %&gt;%
           dplyr::filter(model == 'augmented') %&gt;%
           dplyr::select(statistic) %&gt;%
           pull() %&gt;%
           as.numeric()

# -----------------------------------------------
# p value
# -----------------------------------------------

df_1 &lt;- 1  # cantidad de parámetros fijos del modelo
df_2 &lt;- 10 # grados de libertad restantes (n_total - df_1 - 1)

pf(f_value, df1 = df_1, df2 = df_2, lower.tail = FALSE)

# -----------------------------------------------
# f critic
# -----------------------------------------------

f_critic &lt;- qf(.975, df1 = df_1, df2 = df_2)

# -----------------------------------------------
# visualization
# -----------------------------------------------

library(ggplot2)
f_m02 &lt;-  ggplot(data.frame(x = c(0, 50)), aes(x)) +
  stat_function(fun = df, args = list(df1 = df_1, df2 = df_2), geom = "area") +
  geom_vline(xintercept = f_value, color = 'red') +
  geom_vline(xintercept = f_critic, color = 'red', linetype = 'dotted') +
  scale_x_continuous(breaks=seq(0, 50, 1)) + 
  # xlim(0,10) +
  ylim(0,1) +
  labs(
    x = 'F Ratio', 
    y = 'density') +
  theme_minimal() +
  theme(
  panel.background = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  axis.text.x=element_text(size=1)
  )

# show plot
f_m02
```

  ]
]

.pull_r_60[

&lt;img src="psi4035_t02_slides_files/figure-html/unnamed-chunk-23-1.png" width="90%" /&gt;

.text_60[
Nota: distrubición de estadístico F. Línea roja es nuestro F observado.
]

]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Modelo no predictivo
]
]
]
.line_space_01[
Cuáles son las chances de un modelo que no ajusta
]


&lt;br&gt;
&lt;br&gt;

---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_40[

.text_80[

```r
#------------------------------------------------------------------------------
# p value de la comparación modelos (m00, m03)
#------------------------------------------------------------------------------

# opciones de consola
options(scipen = 999)
options(digits = 7)

# valor p de la comparación de modelos
anova(m00, m03) %&gt;%
broom::tidy() %&gt;%
knitr::kable(., digits = 7)

# -----------------------------------------------
# f value
# -----------------------------------------------

f_value_null &lt;- anova(m00, m03) %&gt;%
                broom::tidy() %&gt;%
                mutate(model = c('compact', 'augmented')) %&gt;%
                dplyr::filter(model == 'augmented') %&gt;%
                dplyr::select(statistic) %&gt;%
                pull() %&gt;%
                as.numeric()

# -----------------------------------------------
# p value
# -----------------------------------------------

df_1 &lt;- 1  # cantidad de parámetros fijos del modelo
df_2 &lt;- 10 # grados de libertad restantes (n_total - df_1 - 1)

pf(f_value_null, df1 = df_1, df2 = df_2, lower.tail = FALSE) %&gt;%
r4sda::decimal(., 7)


# -----------------------------------------------
# f critic
# -----------------------------------------------

f_critic &lt;- qf(.975, df1 = df_1, df2 = df_2)

# -----------------------------------------------
# visualization
# -----------------------------------------------

library(ggplot2)
f_m03 &lt;- ggplot(data.frame(x = c(0, 50)), aes(x)) +
  stat_function(fun = df, args = list(df1 = df_1, df2 = df_2), geom = "area") +
  geom_vline(xintercept = f_value_null, color = 'red') +
  geom_vline(xintercept = f_critic, color = 'red', linetype = 'dotted') +
  scale_x_continuous(breaks=seq(0, 50, 1)) + 
  # xlim(0,10) +
  ylim(0,1) +
  labs(
    x = 'F Ratio', 
    y = 'density') +
  theme_minimal() +
  theme(
  panel.background = element_blank(),
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  axis.text.x=element_text(size=1)
  )


# show plot
f_m03
```

  ]
]

.pull_r_60[

&lt;img src="psi4035_t02_slides_files/figure-html/unnamed-chunk-25-1.png" width="90%" /&gt;

.text_60[
Nota: distrubición de estadístico F. Línea roja es nuestro F del modelo m03.
]

]


.pull_l_50[

#### Modelo de interés `m02`

&lt;img src="psi4035_t02_slides_files/figure-html/unnamed-chunk-26-1.png" width="95%" /&gt;

.text_60[
Nota: distrubición de estadístico F. Línea roja es nuestro F observado.
]

]

.pull_r_50[

#### Modelo no predictivo `m03`

&lt;img src="psi4035_t02_slides_files/figure-html/unnamed-chunk-27-1.png" width="95%" /&gt;

.text_60[
Nota: distrubición de estadístico F. Línea roja es nuestro F del modelo m03.
]

]

---


class: middle, inverse

background-image: url(img/background_02.jpeg)
background-size: 100%


.line_space_01[
Taller
]
.line_space_01[
.text_250[
.bold_white[
Correlaciones
]
]
]
.line_space_01[
Cuáles son las chances de un modelo que no ajusta
]


&lt;br&gt;
&lt;br&gt;

---

#### Correlaciones esperadas

&lt;img src="./files/correlations_navarro_2019.jpg" width="35%" /&gt;

.right[
.text_60[
Referencias: Navarro (2019)
  ]

  ]

]

---

#### Correlaciones no esperadas

&lt;img src="./files/odd_correlations.jpg" width="60%" /&gt;

.right[
.text_60[
Referencias: Franconeri et al. (2021)
  ]

  ]

]

---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_50_t_080[

#### Correlaciones


```r
#------------------------------------------------------------------------------
# datos
#------------------------------------------------------------------------------

#----------------------------------------------------------
# tabla 3.2
#----------------------------------------------------------

data_table_3_2 &lt;- read.table(
text="
person   y    x    x_q   xy   z
1        2    8     64   16   1
2        3    9     81   27   2
3        3    9     81   27   1
4        4   10    100   40   2
5        7    6     36   42   1
6        5    7     49   35   2
7        5    4     16   20   1
8        7    5     25   35   2
9        8    3      9   24   1
10       9    1      1    9   2
11       9    2      4   18   1
12      10    2      4   20   2

",
header=TRUE, stringsAsFactors = FALSE)

# Nota: agregamos a la variable z,
#       para ilustrar como se ve un
#       modelo que no explica a y.

#----------------------------------------------------------
# preparar datos
#----------------------------------------------------------

library(dplyr)
data_model &lt;- data_table_3_2 %&gt;%
              mutate(x_g = mean(x, na.rm = TRUE)) %&gt;%
              mutate(x_cgm = x - x_g) %&gt;%
              dplyr::select(y, x, x_cgm, z)


#----------------------------------------------------------
# correlación base::cor
#----------------------------------------------------------

cor(data_model$y, data_model$x)

#----------------------------------------------------------
# correlación base::cor.test
#----------------------------------------------------------

cor.test(data_model$y, data_model$x)
```

]

.pull_r_50_t_080[

#### Output

```text
&gt; #----------------------------------------------------------
&gt; # tabla 3.2
&gt; #----------------------------------------------------------
&gt; 
&gt; data_table_3_2 &lt;- read.table(
+ text="
+ person   y    x    x_q   xy   z
+ 1        2    8     64   16   1
+ 2        3    9     81   27   2
+ 3        3    9     81   27   1
+ 4        4   10    100   40   2
+ 5        7    6     36   42   1
+ 6        5    7     49   35   2
+ 7        5    4     16   20   1
+ 8        7    5     25   35   2
+ 9        8    3      9   24   1
+ 10       9    1      1    9   2
+ 11       9    2      4   18   1
+ 12      10    2      4   20   2
+ 
+ ",
+ header=TRUE, stringsAsFactors = FALSE)
&gt; 
&gt; # Nota: agregamos a la variable z,
&gt; #       para ilustrar como se ve un
&gt; #       modelo que no explica a y.
&gt; 
&gt; #----------------------------------------------------------
&gt; # preparar datos
&gt; #----------------------------------------------------------
&gt; 
&gt; library(dplyr)
&gt; data_model &lt;- data_table_3_2 %&gt;%
+               mutate(x_g = mean(x, na.rm = TRUE)) %&gt;%
+               mutate(x_cgm = x - x_g) %&gt;%
+               dplyr::select(y, x, x_cgm, z)
&gt; 
&gt; 
&gt; #----------------------------------------------------------
&gt; # correlación base::cor
&gt; #----------------------------------------------------------
&gt; 
&gt; cor(data_model$y, data_model$x)
[1] -0.8971007
&gt; 
&gt; #----------------------------------------------------------
&gt; # correlación base::cor.test
&gt; #----------------------------------------------------------
&gt; 
&gt; cor.test(data_model$y, data_model$x)

  Pearson's product-moment correlation

data:  data_model$y and data_model$x
t = -6.4208, df = 10, p-value = 7.627e-05
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.9710564 -0.6661805
sample estimates:
       cor 
-0.8971007 



```

]



---

background-image: url(img/background_03.jpeg)
background-size: 100%


.pull_l_50_t_080[

#### Diagonal inferior de correlaciones


```r
#------------------------------------------------------------------------------
# datos
#------------------------------------------------------------------------------

#----------------------------------------------------------
# tabla 3.2
#----------------------------------------------------------

data_table_3_2 &lt;- read.table(
text="
person   y    x    x_q   xy   z
1        2    8     64   16   1
2        3    9     81   27   2
3        3    9     81   27   1
4        4   10    100   40   2
5        7    6     36   42   1
6        5    7     49   35   2
7        5    4     16   20   1
8        7    5     25   35   2
9        8    3      9   24   1
10       9    1      1    9   2
11       9    2      4   18   1
12      10    2      4   20   2

",
header=TRUE, stringsAsFactors = FALSE)

# Nota: agregamos a la variable z,
#       para ilustrar como se ve un
#       modelo que no explica a y.

#----------------------------------------------------------
# preparar datos
#----------------------------------------------------------

library(dplyr)
data_model &lt;- data_table_3_2 %&gt;%
              mutate(x_g = mean(x, na.rm = TRUE)) %&gt;%
              mutate(x_cgm = x - x_g) %&gt;%
              dplyr::select(y, x, x_cgm, z)

#----------------------------------------------------------
# con corrr::correlate
#----------------------------------------------------------

data_model %&gt;%
corrr::correlate() %&gt;%
corrr::shave()  %&gt;%
corrr::fashion()
```

]

.pull_r_50_t_080[

#### Output

```text

&gt; #------------------------------------------------------------------------------
&gt; # datos
&gt; #------------------------------------------------------------------------------
&gt; 
&gt; #----------------------------------------------------------
&gt; # tabla 3.2
&gt; #----------------------------------------------------------
&gt; 
&gt; data_table_3_2 &lt;- read.table(
+ text="
+ person   y    x    x_q   xy   z
+ 1        2    8     64   16   1
+ 2        3    9     81   27   2
+ 3        3    9     81   27   1
+ 4        4   10    100   40   2
+ 5        7    6     36   42   1
+ 6        5    7     49   35   2
+ 7        5    4     16   20   1
+ 8        7    5     25   35   2
+ 9        8    3      9   24   1
+ 10       9    1      1    9   2
+ 11       9    2      4   18   1
+ 12      10    2      4   20   2
+ 
+ ",
+ header=TRUE, stringsAsFactors = FALSE)
&gt; 
&gt; # Nota: agregamos a la variable z,
&gt; #       para ilustrar como se ve un
&gt; #       modelo que no explica a y.
&gt; 
&gt; #----------------------------------------------------------
&gt; # preparar datos
&gt; #----------------------------------------------------------
&gt; 
&gt; library(dplyr)
&gt; data_model &lt;- data_table_3_2 %&gt;%
+               mutate(x_g = mean(x, na.rm = TRUE)) %&gt;%
+               mutate(x_cgm = x - x_g) %&gt;%
+               dplyr::select(y, x, x_cgm, z)
&gt; 
&gt; #----------------------------------------------------------
&gt; # con corrr::correlate
&gt; #----------------------------------------------------------
&gt; 
&gt; data_model %&gt;%
+ corrr::correlate() %&gt;%
+ corrr::shave()  %&gt;%
+ corrr::fashion()

Correlation method: 'pearson'
Missing treated using: 'pairwise.complete.obs'

   term    y    x x_cgm z
1     y                  
2     x -.90             
3 x_cgm -.90 1.00        
4     z  .13  .06   .06  

```

]

---



class: inverse split-two


background-image: url(img/background_02.jpeg)
background-size: 100%


.column[
.pull_l_50_1[

.text_180[
.bold_white[
&lt;br&gt;
Muchas gracias!
    ]
  ]
]

.pull_l_50_2[
.line_space_03[
.text_60[

*Carrasco, D., PhD*

*Centro de Medición MIDE UC,*

*Pontificia Universidad Católica de Chile*

https://dacarras.github.io/
    ]
    ]
  ]
]








.column[

.text_180[
.bold_white[
&lt;br&gt;
Referencias
  ]
]

.text_80[
.french[


Franconeri, S. L., Padilla, L. M., Shah, P., Zacks, J. M., &amp; Hullman, J. (2021). The Science of Visual Data Communication: What Works. Psychological Science in the Public Interest, 22(3), 110–161. https://doi.org/10.1177/15291006211051956

Huck, S. W. (2012). Bivariate, Multiple, and Logistic Regression. In Reading Statistics and Research (6th ed., pp. 367–403). Pearson Education.

Navarro, D. (2013). Learning statistics with R: A tutorial for psychology students and other beginners.

Vik, P. (2014). Regression, ANOVA, and the general linear model: A statistics primer. Sage.


  ] 
 ]
]











    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"slideNumberFormat": "%current%",
"countIncrementalSlides": true,
"ratio": "16:9",
"navigation": {
"scroll": true
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
